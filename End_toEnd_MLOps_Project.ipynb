{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPuMXSlwMjOaXEnRB0EIj3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirmahdiKhosravi/end-to-end-MLOps-project/blob/main/End_toEnd_MLOps_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup for our project:"
      ],
      "metadata": {
        "id": "5mjSMvcL5RPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install \"zenml[server]\"\n",
        "!zenml integration install sklearn -y\n",
        "%pip install pyparsing==2.4.2\n",
        "\n",
        "import IPython\n",
        "\n",
        "IPython.Application.instance().kernel.do_shutdown(restart=True)"
      ],
      "metadata": {
        "id": "UYMduNIW5T4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NGROK_TOKEN = \"2Ze6COEBPZorYjW9mcX2NxGXkd0_5VjfzGigf1Q8wPQywZAmr\""
      ],
      "metadata": {
        "id": "tpduJubB9TKk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zenml.environment import Environment\n",
        "\n",
        "if Environment.in_google_colab():\n",
        "  !pip install pyngrok\n",
        "  !ngrok authtoken {NGROK_TOKEN}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mub0ir8XH8Xg",
        "outputId": "aef521a8-c64e-4c2f-e2cc-4e12223045a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mNumExpr defaulting to 2 threads.\u001b[0m\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.0.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install zenml"
      ],
      "metadata": {
        "id": "9lKF9wIbKSu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ZenML setup:"
      ],
      "metadata": {
        "id": "mcgskHAEKHbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf .zen\n",
        "!zenml init"
      ],
      "metadata": {
        "id": "4DXqnH67Kh2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example experimentation ML code:"
      ],
      "metadata": {
        "id": "bcH85d8GLR9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_test():\n",
        "  digits = load_digits()\n",
        "  data = digits.images.reshape((len(digits.images), -1))\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "      data, digits.target, test_size=0.2, shuffle=False\n",
        "  )\n",
        "  model = SVC(gamma=0.001)\n",
        "  model.fit(X_train, y_train)\n",
        "  test_acc = model.score(X_test, y_test)\n",
        "  print(f\"model accuracy: {test_acc}\")\n",
        "\n",
        "train_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnOKXPNjKyOQ",
        "outputId": "4f3b86da-53de-4fa2-b307-86283a36c537"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy: 0.9583333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are to turn this simple experiment into ML pipeline with ZenML. this pipeline will automate the process of loading the data, training a model and evaluating it."
      ],
      "metadata": {
        "id": "pL1jssyLSC2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zenml import step\n",
        "from typing_extensions import Annotated\n",
        "import pandas as pd\n",
        "from typing import Tuple\n",
        "\n",
        "@step\n",
        "def importer() -> Tuple[\n",
        "    Annotated[np.ndarray, \"X_train\"],\n",
        "    Annotated[np.ndarray, \"X_test\"],\n",
        "    Annotated[np.ndarray, \"y_train\"],\n",
        "    Annotated[np.ndarray, \"x_test\"]\n",
        "]:\n",
        "\n",
        "  digits = load_digits()\n",
        "  data = digits.images.reshape((len(digits.images), -1))\n",
        "  X_train, X_test, y_train, y_test = train_test_split(data, digits.target, test_size=0.2, shuffle = False)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "@step\n",
        "def SVC_trainer(X_train: np.ndarray, y_train : np.ndarray) -> ClassifierMixin:\n",
        "  model = SVC(gamma=0.001)\n",
        "  model.fit(X_train, y_train)\n",
        "  return model\n",
        "\n",
        "@step\n",
        "def evaluator(X_test: np.ndarray, y_test : np.ndarray, model : ClassifierMixin) -> float:\n",
        "  model_acc = model.score(X_test, y_test)\n",
        "  print(f\"Model accuracy: {model_acc}\")\n",
        "  return model_acc"
      ],
      "metadata": {
        "id": "tn5TNj4DXNVX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating zenML pipeline:"
      ],
      "metadata": {
        "id": "HOF3GmbidckF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zenml import pipeline\n",
        "\n",
        "@pipeline\n",
        "def digits_pipeline():\n",
        "  X_train, X_test, y_train, y_test = importer()\n",
        "  model = SVC_trainer(X_train, y_train)\n",
        "  evaluator(X_test, y_test, model)"
      ],
      "metadata": {
        "id": "BXzxJmwsdg1y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running zenML pipeline:"
      ],
      "metadata": {
        "id": "hkyHZgNz0ZQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits_SVC_pipeline = digits_pipeline()\n",
        "#digits_SVC_pipeline.run(unlisted=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PNORXy5xRuT",
        "outputId": "5f1d2716-f6cd-4b7f-806a-8bd759dc9392"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mdigits_pipeline\u001b[1;35m.\u001b[0m\n",
            "\u001b[1;35mReusing registered version: \u001b[0m\u001b[1;36m(version: 1)\u001b[1;35m.\u001b[0m\n",
            "\u001b[1;35mExecuting a new run.\u001b[0m\n",
            "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
            "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
            "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
            "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
            "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mimporter\u001b[1;35m.\u001b[0m\n",
            "\u001b[1;35mStep \u001b[0m\u001b[1;36mimporter\u001b[1;35m has started.\u001b[0m\n",
            "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mSVC_trainer\u001b[1;35m.\u001b[0m\n",
            "\u001b[1;35mLinking artifact \u001b[0m\u001b[1;36moutput\u001b[1;35m to model \u001b[0m\u001b[1;36mNone\u001b[1;35m version \u001b[0m\u001b[1;36mNone\u001b[1;35m implicitly.\u001b[0m\n",
            "\u001b[1;35mStep \u001b[0m\u001b[1;36mSVC_trainer\u001b[1;35m has started.\u001b[0m\n",
            "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mevaluator\u001b[1;35m.\u001b[0m\n",
            "\u001b[1;35mLinking artifact \u001b[0m\u001b[1;36moutput\u001b[1;35m to model \u001b[0m\u001b[1;36mNone\u001b[1;35m version \u001b[0m\u001b[1;36mNone\u001b[1;35m implicitly.\u001b[0m\n",
            "\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluator\u001b[1;35m has started.\u001b[0m\n",
            "\u001b[1;35mRun \u001b[0m\u001b[1;36mdigits_pipeline-2023_12_17-22_05_39_817528\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.441s\u001b[1;35m.\u001b[0m\n",
            "\u001b[1;35mYou can visualize your pipeline runs in the \u001b[0m\u001b[1;36mZenML Dashboard\u001b[1;35m. In order to try it locally, please run \u001b[0m\u001b[1;36mzenml up\u001b[1;35m.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now with following code we can visualize zenML the pipeline in zenML dashboard. the username is loca and the password should be left empty."
      ],
      "metadata": {
        "id": "uxANaADb0cfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zenml.environment import Environment\n",
        "\n",
        "def start_zenml_dashboard(port=8237):\n",
        "  if Environment.in_google_colab():\n",
        "    from pyngrok import ngrok\n",
        "\n",
        "    public_url = ngrok.connect(port)\n",
        "    print(f\"use this url instead: {public_url}\")\n",
        "    !zenml up --blocking --port {port}\n",
        "\n",
        "  else:\n",
        "    !zenml up --port {port}\n",
        "\n",
        "start_zenml_dashboard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WurMTilX071t",
        "outputId": "4a207080-bb59-486a-a4ea-679cc7e7b922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.ngrok:Opening tunnel named: http-8237-7f6f51c1-90a7-4e97-bd20-31cd3b2329b1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mOpening tunnel named: http-8237-7f6f51c1-90a7-4e97-bd20-31cd3b2329b1\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=\"no configuration paths supplied\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=\"no configuration paths supplied\"\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=\"client session established\" obj=tunnels.session obj=csess id=6963412f09e5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=\"client session established\" obj=tunnels.session obj=csess id=6963412f09e5\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=start pg=/api/tunnels id=d4303ec5274c8d1d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=start pg=/api/tunnels id=d4303ec5274c8d1d\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=end pg=/api/tunnels id=d4303ec5274c8d1d status=200 dur=350.232µs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=end pg=/api/tunnels id=d4303ec5274c8d1d status=200 dur=350.232µs\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=start pg=/api/tunnels id=847bba54d5a2642d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=start pg=/api/tunnels id=847bba54d5a2642d\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=end pg=/api/tunnels id=847bba54d5a2642d status=200 dur=111.414µs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=end pg=/api/tunnels id=847bba54d5a2642d status=200 dur=111.414µs\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=start pg=/api/tunnels id=5453a2b8cdf66fd7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=start pg=/api/tunnels id=5453a2b8cdf66fd7\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-8237-7f6f51c1-90a7-4e97-bd20-31cd3b2329b1 addr=http://localhost:8237 url=https://aa90-34-147-59-123.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use this url instead: NgrokTunnel: \"https://aa90-34-147-59-123.ngrok-free.app\" -> \"http://localhost:8237\"\n",
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-8237-7f6f51c1-90a7-4e97-bd20-31cd3b2329b1 addr=http://localhost:8237 url=https://aa90-34-147-59-123.ngrok-free.app\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2023-12-17T22:23:59+0000 lvl=info msg=end pg=/api/tunnels id=5453a2b8cdf66fd7 status=201 dur=106.648958ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mt=2023-12-17T22:23:59+0000 lvl=info msg=end pg=/api/tunnels id=5453a2b8cdf66fd7 status=201 dur=106.648958ms\u001b[0m\n",
            "\u001b[1;35mNumExpr defaulting to 2 threads.\u001b[0m\n",
            "\u001b[1;35mUpdating the local ZenML server.\u001b[0m\n",
            "\u001b[?25l\u001b[32m⠋\u001b[0m Stopping service 'LocalZenServer[9a4ac2eb-dad5-4747-8f30-5e622a95d211] (type: zen_server, flavor: \n",
            "local)'.\n",
            "\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;35mStarting ZenML Server as blocking process... press CTRL+C once to stop it.\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m32915\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8237\u001b[0m (Press CTRL+C to quit)\n"
          ]
        }
      ]
    }
  ]
}